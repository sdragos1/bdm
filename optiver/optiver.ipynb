{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "534a0c9f",
      "metadata": {
        "id": "534a0c9f"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "21546ff3",
      "metadata": {
        "id": "21546ff3"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "kaggle = False\n",
        "colab = True\n",
        "\n",
        "is_train = True\n",
        "\n",
        "if kaggle:\n",
        "    print(\"Running in Kaggle environment...\")\n",
        "    comp_path = \"/kaggle/input/optiver-trading-at-the-close/\"\n",
        "    train_path = f\"{comp_path}/train.csv\"\n",
        "    models_path = f\"{comp_path}/models/\"\n",
        "\n",
        "if colab:\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    mount_path = f\"/content/drive/\"\n",
        "\n",
        "    if not os.path.ismount(mount_path):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount(mount_path, force_remount=True)\n",
        "    comp_path = f\"{mount_path}MyDrive/optiver\"\n",
        "\n",
        "if is_train:\n",
        "  dates_train = [0,390]\n",
        "  dates_test = [391,480]\n",
        "else:\n",
        "  dates_train = [0,480]\n",
        "  dates_test = [-1,-1]\n",
        "\n",
        "models_path = f\"{comp_path}/models/\"\n",
        "train_path = f\"{comp_path}/train.csv\"\n",
        "train_eng_path = f\"{comp_path}/train_eng.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "be2a6770",
      "metadata": {
        "id": "be2a6770"
      },
      "outputs": [],
      "source": [
        "#@title Read train data\n",
        "\n",
        "def read_train() -> pd.DataFrame:\n",
        "  train_df = pd.read_csv(train_path).drop(['row_id'], axis=1)\n",
        "  print(train_df.count())\n",
        "  print(train_df.dtypes)\n",
        "  print(f\"Rows:\\n{train_df.isnull().sum()}\")\n",
        "  print(f\"Total NaN values: {train_df.isnull().sum().sum()}\")\n",
        "\n",
        "  train_df = train_df.dropna(subset=[\"ask_price\"])\n",
        "  train_df.loc[train_df['seconds_in_bucket'] <= 300, \"near_price\"] = 0\n",
        "  train_df.loc[train_df['seconds_in_bucket'] <= 300, \"far_price\"] = 0\n",
        "  train_df['far_price'] = train_df['far_price'].interpolate()\n",
        "\n",
        "  print(f\"Total NaN values after preprocessing: {train_df.isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Util functions\n",
        "def save_pickle(data, file_path):\n",
        "  directory = os.path.dirname(file_path)\n",
        "  if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "  with open(file_path, 'wb') as file:\n",
        "      pickle.dump(data, file)\n",
        "  print(f\"Data saved to {file_path}\")\n",
        "\n",
        "def load_pickle(file_path):\n",
        "  if os.path.exists(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "      data = pickle.load(file)\n",
        "    return data\n",
        "  else:\n",
        "    raise FileNotFoundError(f\"No such file: {file_path}\")\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose:\n",
        "        print(f'Mem. usage decreased to {end_mem:.2f} Mb ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
        "    return df"
      ],
      "metadata": {
        "id": "_pMVokYQgI7p"
      },
      "id": "_pMVokYQgI7p",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "gO3jebNUo2WU"
      },
      "id": "gO3jebNUo2WU"
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/competitions/optiver-trading-at-the-close/discussion/442851\n",
        "stock_weights = [\n",
        "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
        "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
        "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
        "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
        "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
        "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
        "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
        "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
        "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
        "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
        "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
        "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
        "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
        "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
        "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
        "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
        "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
        "]\n",
        "stock_weights = {int(k):v for k,v in enumerate(stock_weights)}"
      ],
      "metadata": {
        "id": "MjMJo0cvo0Td"
      },
      "id": "MjMJo0cvo0Td",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(df) -> pd.DataFrame:\n",
        "  df[\"volume\"] = df[\"ask_size\"] + df[\"bid_size\"]\n",
        "  df[\"mid_price\"] = (df[\"ask_price\"] + df[\"bid_price\"]) / 2\n",
        "\n",
        "  df['bid_ask_spread'] = df['ask_price'] - df['bid_price']\n",
        "  df['bid_ask_ratio'] = df['bid_price'] / df['ask_price']\n",
        "  df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
        "  df[\"market_urgency\"] = df[\"bid_ask_spread\"] * df[\"liquidity_imbalance\"]\n",
        "\n",
        "  df[\"market_urgency_v2\"] = (df[\"ask_price\"]+df[\"bid_price\"])/2 - (df[\"bid_price\"]*df[\"bid_size\"]+df[\"ask_price\"]*df[\"ask_size\"]) / (df[\"bid_size\"]+df[\"ask_size\"])\n",
        "  df[\"stock_weights\"] = df[\"stock_id\"].map(stock_weights)\n",
        "  df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n",
        "\n",
        "  ss = df.groupby('time_id')['weighted_wap'].sum()/df.groupby('time_id')['stock_weights'].sum()\n",
        "  ss = ss.reset_index()\n",
        "  ss.columns = ['time_id','indexwap']\n",
        "\n",
        "  df = pd.merge(df,ss,how='left',on='time_id')\n",
        "  df['indexwapdiff'] = df['wap'] - df['indexwap']\n",
        "\n",
        "  global_stock_id_feats = {\n",
        "      \"median_size\": df.groupby(\"stock_id\")[\"bid_size\"].median() + df.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
        "      \"std_size\": df.groupby(\"stock_id\")[\"bid_size\"].std() + df.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
        "      \"ptp_size\": df.groupby(\"stock_id\")[\"bid_size\"].max() - df.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
        "      \"median_price\": df.groupby(\"stock_id\")[\"bid_price\"].median() + df.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
        "      \"std_price\": df.groupby(\"stock_id\")[\"bid_price\"].std() + df.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
        "      \"ptp_price\": df.groupby(\"stock_id\")[\"bid_price\"].max() - df.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
        "  }\n",
        "\n",
        "  for key, value in global_stock_id_feats.items():\n",
        "      df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())"
      ],
      "metadata": {
        "id": "wvuxt1OXRaAN"
      },
      "id": "wvuxt1OXRaAN",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(train_eng_path):\n",
        "  print(f'Found existing data saved in {train_eng_path}, loading...')\n",
        "  train_df = load_pickle(train_eng_path)\n",
        "else:\n",
        "  train_df = read_train()\n",
        "  train_df = feature_engineering(train_df)\n",
        "  train_df = reduce_mem_usage(train_df, verbose=True)\n",
        "  save_pickle(train_df, train_eng_path)\n",
        "\n",
        "print(train_df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbuxDMOgx-b",
        "outputId": "e7bbcc05-ef1d-40eb-a5b1-e7cc77ef17c6"
      },
      "id": "wLbuxDMOgx-b",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing data saved in /content/drive/MyDrive/optiver/train_eng.pkl, loading...\n",
            "stock_id                     int16\n",
            "date_id                      int16\n",
            "seconds_in_bucket            int16\n",
            "imbalance_size             float32\n",
            "imbalance_buy_sell_flag       int8\n",
            "reference_price            float32\n",
            "matched_size               float32\n",
            "far_price                  float32\n",
            "near_price                 float32\n",
            "bid_price                  float32\n",
            "bid_size                   float32\n",
            "ask_price                  float32\n",
            "ask_size                   float32\n",
            "wap                        float32\n",
            "target                     float32\n",
            "time_id                      int16\n",
            "volume                     float32\n",
            "mid_price                  float32\n",
            "bid_ask_spread             float32\n",
            "bid_ask_ratio              float32\n",
            "liquidity_imbalance        float32\n",
            "market_urgency             float32\n",
            "market_urgency_v2          float32\n",
            "stock_weights              float32\n",
            "weighted_wap               float32\n",
            "indexwap                   float32\n",
            "indexwapdiff               float32\n",
            "global_median_size         float32\n",
            "global_std_size            float32\n",
            "global_ptp_size            float32\n",
            "global_median_price        float32\n",
            "global_std_price           float32\n",
            "global_ptp_price           float32\n",
            "dtype: object\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}