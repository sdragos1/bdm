{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd243c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME: str = \"web_graphs\"\n",
    "HDFS_NAMENODE: str = \"hdfs://namenode:9000\"\n",
    "INPUT_DIR: str = f\"{HDFS_NAMENODE}/input/{PROJECT_NAME}\"\n",
    "OUTPUT_DIR: str = f\"{HDFS_NAMENODE}/output/{PROJECT_NAME}\"\n",
    "\n",
    "MASTER_URI = \"spark://spark-master:7077\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12e4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def spark_session() -> SparkSession:\n",
    "    spark = (\n",
    "        SparkSession.builder.appName(PROJECT_NAME.capitalize)\n",
    "        .master(MASTER_URI)\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", HDFS_NAMENODE)\n",
    "        .config(\"spark.hadoop.dfs.client.use.datanode.hostname\", \"true\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    print(f\"Connected to Spark {spark.version}\")\n",
    "\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f60b5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB_DATA_PATH = f\"{INPUT_DIR}/web-Google.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b02180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "def load_web_data(spark: SparkSession) -> DataFrame:\n",
    "    raw_data = spark.read.text(WEB_DATA_PATH)\n",
    "    edges_df = (\n",
    "        raw_data.filter(~col(\"value\").startswith(\"#\"))\n",
    "        .selectExpr(\n",
    "            \"split(value, '\\\\t')[0] as FromNodeID\", \"split(value, '\\\\t')[1] as ToNodeID\"\n",
    "        )\n",
    "        .withColumn(\"FromNodeID\", col(\"FromNodeID\").cast(IntegerType()))\n",
    "        .withColumn(\"ToNodeID\", col(\"ToNodeID\").cast(IntegerType()))\n",
    "        .cache()\n",
    "    )\n",
    "\n",
    "    return edges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3a967",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Given the Google web graph dataset, please output the sorted list of web pages with the number of outlinks, sorted in descending order of the out-degrees.\n",
    "\n",
    "## Output Format\n",
    "a sorted list of pages with their out-degrees\n",
    "Each line contains: <NodeID>, <out-degree> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "037135e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Spark 3.5.0\n",
      "+----------+---------+\n",
      "|FromNodeID|OutDegree|\n",
      "+----------+---------+\n",
      "|    506742|      456|\n",
      "|    203748|      372|\n",
      "|    305229|      372|\n",
      "|    768091|      330|\n",
      "|    808643|      277|\n",
      "|    412410|      268|\n",
      "|    600479|      265|\n",
      "|    376428|      258|\n",
      "|    156950|      257|\n",
      "|    885728|      256|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Writing results to 'hdfs://namenode:9000/output/web_graphs/node_out_degree'\n",
      "\n",
      "CPU times: user 35.6 ms, sys: 16.3 ms, total: 51.8 ms\n",
      "Wall time: 5.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "spark = spark_session()\n",
    "\n",
    "edges_df = load_web_data(spark)\n",
    "\n",
    "result_df = (\n",
    "    edges_df.groupBy(\"FromNodeID\")\n",
    "    .agg(count(\"ToNodeID\").alias(\"OutDegree\"))\n",
    "    .orderBy(col(\"OutDegree\").desc())\n",
    "    .select([\"FromNodeID\", \"OutDegree\"])\n",
    ")\n",
    "result_df.cache()\n",
    "\n",
    "result_df.show(n=10)\n",
    "print(f\"Writing results to '{OUTPUT_DIR}/node_out_degree'\\n\")\n",
    "result_df.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}/node_out_degree\", header=True, sep=\",\"\n",
    ")\n",
    "\n",
    "result_df.unpersist()\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
