{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f06c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME: str = \"recommender_system\"\n",
    "HDFS_NAMENODE: str = \"hdfs://namenode:9000\"\n",
    "INPUT_DIR: str = f\"{HDFS_NAMENODE}/input/{PROJECT_NAME}\"\n",
    "OUTPUT_DIR: str = f\"{HDFS_NAMENODE}/output/{PROJECT_NAME}\"\n",
    "\n",
    "MASTER_URI = \"spark://spark-master:7077\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d491642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    ")\n",
    "\n",
    "userSchema = StructType(\n",
    "    [\n",
    "        StructField(\"UserID\", IntegerType(), True),\n",
    "        StructField(\"Gender\", StringType(), True),\n",
    "        StructField(\"Age\", IntegerType(), True),\n",
    "        StructField(\"Occupation\", StringType(), True),\n",
    "        StructField(\"Zip_code\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "movieSchema = StructType(\n",
    "    [\n",
    "        StructField(\"MovieID\", IntegerType(), True),\n",
    "        StructField(\"Title\", StringType(), True),\n",
    "        StructField(\"Genres\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ratingSchema = StructType(\n",
    "    [\n",
    "        StructField(\"UserID\", IntegerType(), True),\n",
    "        StructField(\"MovieID\", IntegerType(), True),\n",
    "        StructField(\"Rating\", IntegerType(), True),\n",
    "        StructField(\"Timestamp\", StringType(), True),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13305105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def spark_session() -> SparkSession:\n",
    "    spark = (\n",
    "        SparkSession.builder.appName(PROJECT_NAME.capitalize)\n",
    "        .master(MASTER_URI)\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", HDFS_NAMENODE)\n",
    "        .config(\"spark.hadoop.dfs.client.use.datanode.hostname\", \"true\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    print(f\"Connected to Spark {spark.version}\")\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Spark 3.5.0\n",
      "Starting data conversion to Parquet...\n",
      "------------------------------\n",
      "Processing: hdfs://namenode:9000/input/recommender_system/ratings.dat\n",
      "Successfully converted to Parquet at: hdfs://namenode:9000/input/recommender_system/ratings_parquet\n",
      "------------------------------\n",
      "Processing: hdfs://namenode:9000/input/recommender_system/users.dat\n",
      "Successfully converted to Parquet at: hdfs://namenode:9000/input/recommender_system/users_parquet\n",
      "------------------------------\n",
      "Processing: hdfs://namenode:9000/input/recommender_system/movies.dat\n",
      "Successfully converted to Parquet at: hdfs://namenode:9000/input/recommender_system/movies_parquet\n",
      "------------------------------\n",
      "All files converted.\n",
      "CPU times: user 10.8 ms, sys: 7.47 ms, total: 18.3 ms\n",
      "Wall time: 3.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "spark = spark_session()\n",
    "\n",
    "\n",
    "def convert_dat_to_parquet(file_name: str, schema: StructType):\n",
    "    input_path = f\"{INPUT_DIR}/{file_name}.dat\"\n",
    "    output_path = f\"{INPUT_DIR}/{file_name}_parquet\"\n",
    "\n",
    "    print(f\"Processing: {input_path}\")\n",
    "\n",
    "    df = spark.read.option(\"sep\", \"::\").csv(input_path, schema=schema)\n",
    "    df.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "    print(f\"Successfully converted to Parquet at: {output_path}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "print(\"Starting data conversion to Parquet...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "convert_dat_to_parquet(\"ratings\", ratingSchema)\n",
    "convert_dat_to_parquet(\"users\", userSchema)\n",
    "convert_dat_to_parquet(\"movies\", movieSchema)\n",
    "\n",
    "print(\"All files converted.\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "312db5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_FILE = f\"{INPUT_DIR}/ratings_parquet\"\n",
    "USERS_FILE = f\"{INPUT_DIR}/users_parquet\"\n",
    "MOVIES_FILE = f\"{INPUT_DIR}/movies_parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafea65e",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "List the top-rated movies by all users. \n",
    "\n",
    "#### Output format\n",
    "A list of <movie, score> pairs\n",
    "sorted in descending order of ‘average’ rating score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff04ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Spark 3.5.0\n",
      "Writing results to 'hdfs://namenode:9000/output/recommender_system/average_movie_ratings'\n",
      "\n",
      "CPU times: user 18.3 ms, sys: 9.51 ms, total: 27.8 ms\n",
      "Wall time: 5.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "spark = spark_session()\n",
    "\n",
    "df = spark.read.parquet(RATINGS_FILE)\n",
    "\n",
    "agg_df = df.groupBy(\"MovieId\").agg(avg(\"Rating\").alias(\"AvgRating\"))\n",
    "\n",
    "sorted_df = agg_df.orderBy(col(\"AvgRating\").desc())\n",
    "\n",
    "sorted_df.cache()\n",
    "\n",
    "sorted_df = sorted_df.select(\n",
    "    col(\"MovieId\").alias(\"movie\"), col(\"AvgRating\").alias(\"score\")\n",
    ")\n",
    "print(f\"Writing results to '{OUTPUT_DIR}/average_movie_ratings'\\n\")\n",
    "sorted_df.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}/average_movie_ratings\", header=True, sep=\",\"\n",
    ")\n",
    "\n",
    "sorted_df.unpersist()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2ece8",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "List the top-rated movies grouped by gender, by age group, and by occupation, respectively. \n",
    "\n",
    "#### Output format\n",
    "3 sorted lists: <movie, gender, score> pairs, <movie, age group, score> pairs, <movie, occupation, score>\n",
    "sorted in descending order of ‘average’ rating score grouped by gender, by age group, and by occupation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78c31e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Spark 3.5.0\n",
      "Listing top rated movies by Gender...\n",
      "Listing top rated movies by Age...\n",
      "Listing top rated movies by Occupation...\n",
      "CPU times: user 33.2 ms, sys: 16.2 ms, total: 49.4 ms\n",
      "Wall time: 8.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql.functions import broadcast, col, avg\n",
    "\n",
    "spark = spark_session()\n",
    "\n",
    "ratings_df = spark.read.parquet(RATINGS_FILE)\n",
    "user_df = spark.read.parquet(USERS_FILE)\n",
    "\n",
    "ratings_users_df = ratings_df.join(broadcast(user_df), on=\"UserId\").select(\n",
    "    [\"MovieId\", \"Rating\", \"Gender\", \"Age\", \"Occupation\"]\n",
    ")\n",
    "\n",
    "\n",
    "def top_rated_movies_grouped_by(category: str):\n",
    "    print(f\"Listing top rated movies by {category}...\")\n",
    "    agg_df = ratings_users_df.groupBy(category, \"MovieID\").agg(\n",
    "        avg(col(\"Rating\")).alias(\"AvgRating\")\n",
    "    )\n",
    "    sorted_df = agg_df.orderBy(col(\"AvgRating\").desc())\n",
    "    sorted_df = sorted_df.select(\n",
    "        col(\"MovieID\").alias(\"movie\"),\n",
    "        col(category).alias(category.lower()),\n",
    "        col(\"AvgRating\").alias(\"score\"),\n",
    "    )\n",
    "\n",
    "    sorted_df.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "        f\"{OUTPUT_DIR}/top_movies_by_{category.lower()}\", header=True, sep=\",\"\n",
    "    )\n",
    "\n",
    "\n",
    "top_rated_movies_grouped_by(\"Gender\")\n",
    "top_rated_movies_grouped_by(\"Age\")\n",
    "top_rated_movies_grouped_by(\"Occupation\")\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8763959",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "List the average rating score of each user for all movies, and grouped by genre, respectively. \n",
    "\n",
    "\n",
    "#### Output format\n",
    "two sorted lists: <user, score> pairs, <user, genre, score> pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "547e22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Spark 3.5.0\n",
      "Computing average rating score of each user for all movies...\n",
      "Computing average rating score of each user for all movies by genre...\n",
      "CPU times: user 31.9 ms, sys: 13.5 ms, total: 45.4 ms\n",
      "Wall time: 5.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spark = spark_session()\n",
    "\n",
    "ratings_df = spark.read.parquet(RATINGS_FILE)\n",
    "movies_df = spark.read.parquet(MOVIES_FILE)\n",
    "\n",
    "user_agg = ratings_df.groupBy(\"UserId\").agg(avg(col(\"Rating\")).alias(\"AvgRating\"))\n",
    "sorted_user_df = user_agg.orderBy(col(\"AvgRating\").desc())\n",
    "\n",
    "sorted_user_df = sorted_user_df.select(\n",
    "    col(\"UserId\").alias(\"user\"), col(\"AvgRating\").alias(\"score\")\n",
    ")\n",
    "\n",
    "ratings_movies_df = ratings_df.join(broadcast(movies_df), on=\"MovieId\").select(\n",
    "    [\"MovieId\", \"Genres\", \"UserId\", \"Rating\"]\n",
    ")\n",
    "ratings_movies_agg = ratings_movies_df.groupBy(\"UserId\", \"Genres\").agg(\n",
    "    avg(col(\"Rating\")).alias(\"AvgRating\")\n",
    ")\n",
    "sorted_ratings_movies_df = ratings_movies_agg.orderBy(col(\"AvgRating\").desc())\n",
    "sorted_ratings_movies_df = sorted_ratings_movies_df.select(\n",
    "    col(\"UserId\").alias(\"user\"),\n",
    "    col(\"Genres\").alias(\"genre\"),\n",
    "    col(\"AvgRating\").alias(\"score\"),\n",
    ")\n",
    "\n",
    "print(\"Computing average rating score of each user for all movies...\")\n",
    "sorted_user_df.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}/average_rating_by_user\", header=True, sep=\",\"\n",
    ")\n",
    "print(\"Computing average rating score of each user for all movies by genre...\")\n",
    "sorted_ratings_movies_df.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "    f\"{OUTPUT_DIR}/average_rating_by_user_and_genre\", header=True, sep=\",\"\n",
    ")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
